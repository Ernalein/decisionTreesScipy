{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df24fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba45fc03",
   "metadata": {},
   "source": [
    "### Node Class\n",
    "\n",
    "Tree structure is build by Node Objects. Each node object has an attribute and a classification when trained, as well as a parent node and the value associated with the parents attribute and a classification.\n",
    "The nodes are trained by tran_data and also offer the printTree function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a76456",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    '''\n",
    "    class Node innitialises a tree structure for a non-binary tree\n",
    "    it has the typical setter and getter methods and a method to remove a \n",
    "    child from the list of children\n",
    "    '''\n",
    "    def __init__(self, parent = None, attribute = None, classification = None, value = None, valueIsContinuous = False, target = None):\n",
    "        self.children = []  \n",
    "        self.parent = parent\n",
    "        self.attribute = attribute\n",
    "        self.classification = classification\n",
    "        self.value = value\n",
    "        self.valueIsContinuous = valueIsContinuous\n",
    "        self.target = target\n",
    "        \n",
    "\n",
    "    def setChild(self, node):\n",
    "        self.children.append(node)\n",
    "        \n",
    "    def setParent(self, node):\n",
    "        if (self.parent is not None):\n",
    "            self.parent.children.remove(self)\n",
    "        self.parent = node\n",
    "\n",
    "    def getChildren(self):\n",
    "        return self.children\n",
    "    \n",
    "    def getParent(self):\n",
    "        return self.parent\n",
    "    \n",
    "    def deleteChild(self, node):\n",
    "        if (node in self.children):\n",
    "            node.parent = None\n",
    "            self.children.remove(node)\n",
    "        else:\n",
    "            raise TypeError(\"Child not in Children\")\n",
    "        \n",
    "    def isLeaf(self):\n",
    "        if len(self.children) > 0:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def isRoot(self):\n",
    "        if (self.parent is None):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def setAttribute(self, attribute):\n",
    "        self.attribute = attribute\n",
    "    \n",
    "    def getAttribute(self):\n",
    "        return self.attribute\n",
    "    \n",
    "    def setClassification(self, classification):\n",
    "        self.classification = classification\n",
    "    \n",
    "    def getClassification(self):\n",
    "        return self.classification\n",
    "    \n",
    "    def setValue(self,value):\n",
    "        self.value = value\n",
    "\n",
    "    def getValue(self):\n",
    "        return self.value\n",
    "    \n",
    "\n",
    "    def printTree(self, level = 0):\n",
    "        tab = \"    \"\n",
    "        if self.isLeaf():\n",
    "            print(tab*level, \"classification: \", self.target, \" = \" , self.classification)\n",
    "        else:\n",
    "            for child in self.children:\n",
    "                \n",
    "                # printing intervals\n",
    "                if child.valueIsContinuous:\n",
    "                    interval = \"\"\n",
    "                    if child.value[0] == np.NINF:\n",
    "                        interval = f\"smaller then {child.value[1]}\"\n",
    "                    elif child.value[1] == np.PINF:\n",
    "                        interval = f\"bigger then {child.value[0]}\"\n",
    "                    else:\n",
    "                        interval = f\"between {child.value[0]} and {child.value[1]}\"\n",
    "                    print(tab*level, self.attribute, \": \", interval)\n",
    "                \n",
    "                # printing discrete values\n",
    "                else:\n",
    "                    print(tab*level, self.attribute, \": \", child.value)\n",
    "                \n",
    "                # traverse deeper into the tree\n",
    "                child.printTree(level + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec05a79",
   "metadata": {},
   "source": [
    "### train_Data Class\n",
    "\n",
    "The class represents a data (sub)set that is used to train the (sub)tree. It has a (root) node which it is responsible to train (choose attribute, classification, and child nodes) via the id3 function.\n",
    "I can also deal with continuous variables by ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8edf112",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_data:\n",
    "    '''\n",
    "    class train_data has all important functions for ID3 Algorithm:\n",
    "    it can calculate the entropy of some data, the information gain, choose an attriute.\n",
    "    within the ID3 algorithm a tree will be trained.\n",
    "    the function retrain(data) retrains a trained tree with new data.\n",
    "    '''\n",
    "    def __init__(self, data, target, attributes, node:Node = None, recursion_depth = None, continuous_splitting = 0.1,  max_recursion = 10):\n",
    "        \n",
    "        self.data = data\n",
    "        if not isinstance(self.data, pd.DataFrame):\n",
    "            raise TypeError(\"Data has to be a Pandas Dataframe\")\n",
    "        \n",
    "        self.target = target\n",
    "        if not isinstance(self.target, str):\n",
    "            raise TypeError(\"Taget has to be of type string\")\n",
    "        \n",
    "        self.attributes = attributes\n",
    "        if not isinstance(attributes, list):\n",
    "            raise TypeError(\"Attributes have to have structure list\")\n",
    "            \n",
    "        for attribute in self.attributes:\n",
    "            if not isinstance(attribute, str):\n",
    "                raise TypeError(\"Attributes have to be of type string\")\n",
    "\n",
    "        self.node = node\n",
    "        self.continuous_splitting = continuous_splitting\n",
    "        self.recursion_depth = recursion_depth\n",
    "        self.max_recursion = max_recursion\n",
    "    \n",
    "    ######################################\n",
    "    ## methods for continuous variables ##\n",
    "    ######################################\n",
    "    \n",
    "    def is_continuous(self, values):\n",
    "        # checks is variable is a continuous variable\n",
    "        # (it is continuous if it has more than 10 different values and is a numericla scalar)\n",
    "        if len(values) > 10:\n",
    "            if isinstance(list(values)[5], int) or isinstance(list(values)[5], float):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    \n",
    "    def getBoundaries(self, tColumn, aColumn):\n",
    "        # by looking at the target column and the attribute column the\n",
    "        # function decides on deciosion boundaries in a continuous varibale, where classification changes\n",
    "        # aColumn -> attribute column with the continuous values\n",
    "        # tColumn -> target column with the classification\n",
    "        \n",
    "        # 1) sort the two columns\n",
    "        columns = pd.DataFrame(data={\"a\":list(aColumn), \"t\":list(tColumn)}).sort_values(by=\"a\")\n",
    "        columns.index = range(len(columns))\n",
    "\n",
    "        # 2) find decision boundaries where classification changes\n",
    "        leftBound = np.NINF\n",
    "        rightBound = None\n",
    "        boundaries = []\n",
    "        currentClass = columns[\"t\"][0]\n",
    "        for i in range(len(columns)):\n",
    "            # when classification changes\n",
    "            if(columns[\"t\"][i] != currentClass):\n",
    "                currentClass = columns[\"t\"][i]\n",
    "                \n",
    "                # get the value in the middel\n",
    "                beforeSwitch = columns[\"a\"][i-1]\n",
    "                afterSwitch = columns[\"a\"][i]\n",
    "                rightBound = (beforeSwitch + afterSwitch) / 2\n",
    "\n",
    "                # safe the tupple of two boundaries with a uniform classification\n",
    "                boundaries.append((leftBound, rightBound))\n",
    "                leftBound = rightBound\n",
    "        \n",
    "        # last tupple that does not get triggerd by a switch of classification\n",
    "        boundaries.append((leftBound, np.PINF))\n",
    "        \n",
    "        # if the getBoundaries function returns more then 10 intervals\n",
    "        # set intervals indipendent of classification\n",
    "        if len(boundaries) > 10:\n",
    "            return self.setBoundaries(aColumn)\n",
    "        \n",
    "        return boundaries\n",
    "    \n",
    "    def setBoundaries(self, aColumn):\n",
    "        # if the getBoundaries function returns more then 10 intervals\n",
    "        # sets intervals indipendent of classification\n",
    "        \n",
    "        # calculate size of intervals\n",
    "        maximum = np.max(aColumn)\n",
    "        minimum = np.min(aColumn)\n",
    "        stepsize = (maximum - minimum)/ 10\n",
    "        boundaries = []\n",
    "        \n",
    "        # make a tupel for each interval\n",
    "        leftBound = np.NINF\n",
    "        rightBound = minimum + stepsize\n",
    "        for i in range(9):\n",
    "            boundaries.append((leftBound, rightBound))\n",
    "            leftBound = rightBound\n",
    "            rightBound = leftBound + stepsize\n",
    "        boundaries.append((leftBound, np.PINF))\n",
    "        \n",
    "        return boundaries\n",
    "        \n",
    "    \n",
    "    def replaceContinuous(self, boundaries, aColumn):\n",
    "        # replaces the continuous values of an attribute by the\n",
    "        # tuples that represent an interval\n",
    "        \n",
    "        newAColumn = []\n",
    "        for value in aColumn:\n",
    "            for l, r in boundaries:\n",
    "                if value >= l and value < r:\n",
    "                    newAColumn.append((l, r))\n",
    "        return newAColumn\n",
    "    \n",
    "    \n",
    "    #######################################\n",
    "    ## methods for choosing an attribute ##\n",
    "    #######################################\n",
    "    \n",
    "    \n",
    "    def entropy(self):\n",
    "        # calculates entropy \n",
    "        targetColumn = self.data.loc[:, self.target]\n",
    "\n",
    "        values = set(targetColumn)\n",
    "        entropySum = 0\n",
    "        for value in values:\n",
    "            p = list(targetColumn).count(value) / len(targetColumn)\n",
    "            entropySum = entropySum + (- p * np.log(p))\n",
    "\n",
    "        return entropySum\n",
    "    \n",
    "\n",
    "    def informationGain(self, attributeColumn, values):\n",
    "        # calculates the informationGain\n",
    "        gainSum = 0\n",
    "        \n",
    "        for value in values:\n",
    "            \n",
    "            subsetData = self.data[attributeColumn == value]\n",
    "            subset = train_data(subsetData, self.target, self.attributes)\n",
    "            # claculate entropy and normalize by size of subsets\n",
    "            gainSum = gainSum + (subsetData.shape[0] / self.data.shape[0]) * subset.entropy()\n",
    "\n",
    "        # substract summed and weighted entropy of subsets from entropy of whole set    \n",
    "        infoGain = self.entropy() - gainSum\n",
    "\n",
    "        return infoGain\n",
    "\n",
    "    def gainRatio(self, attributeColumn, values):\n",
    "        # calculating the Gain Ratio instead of the InforamtionGain\n",
    "        # to prefer attributes with few values\n",
    "        \n",
    "        infoGain = self.informationGain(attributeColumn, values)\n",
    "\n",
    "        splitInfo = 0\n",
    "        for value in values:\n",
    "            subset = attributeColumn[attributeColumn == value]\n",
    "            # proportion of subset size and whole set size\n",
    "            s = len(subset) / len(attributeColumn)\n",
    "            print(\"size proportion:\", s)\n",
    "            print(\"for value \", value ,\" in \", attributeColumn)\n",
    "            splitInfo = splitInfo + (- s * np.log(s))\n",
    "            \n",
    "        \n",
    "        if splitInfo == 0:\n",
    "            splitInfo = infoGain\n",
    "            \n",
    "        return infoGain / splitInfo\n",
    "        \n",
    "\n",
    "    def chooseAttribute(self):\n",
    "        # chooses an attribute that maximises GainRatio\n",
    "        \n",
    "        maxGain= 0\n",
    "        maxAttribute = \"\"\n",
    "\n",
    "        # calculate Gain Ratio for each attribute\n",
    "        for attribute in self.attributes:\n",
    "            \n",
    "            print(\"--------------------------------------------------------------------------\")\n",
    "            attributeColumn = self.data.loc[:, attribute]\n",
    "            values = set(attributeColumn)\n",
    "            gain = 0\n",
    "\n",
    "            # replace the values in attributeColumn with continuous values by Intervals\n",
    "            print(f\"{attribute} is continuous and has {len(values)} values: {self.is_continuous(values)}\")\n",
    "            if self.is_continuous(values):\n",
    "                targetColumn = self.data[self.target]\n",
    "                boundaries = self.getBoundaries(targetColumn, attributeColumn)\n",
    "                attributeColumn = self.replaceContinuous(boundaries, attributeColumn)\n",
    "                values = set(attributeColumn)\n",
    "                print(\"\")\n",
    "                print(f\"replaced values of {attribute} by intervals: \\n{values}\")\n",
    "                print(\"\")                \n",
    "                \n",
    "            # calculate gainRatio\n",
    "            gain = self.gainRatio(attributeColumn, values)\n",
    "\n",
    "            # store attribute with highest information gain\n",
    "            if gain >= maxGain:\n",
    "                maxGain = gain\n",
    "                maxAttribute = attribute\n",
    "\n",
    "        # choose attribute with highest Information Gain\n",
    "        return maxAttribute\n",
    "\n",
    "    ############################################\n",
    "    ## methods for building the decision tree ##\n",
    "    ############################################\n",
    "    \n",
    "    def classify(self):\n",
    "        # returns the most commen classification of the dataset\n",
    "        \n",
    "        targetColumn = self.data.loc[:, self.target]\n",
    "        values = set(targetColumn)\n",
    "        maxClass = 0  # highest number of values\n",
    "        classification = \"\" # classification of most common value\n",
    "        for value in values:\n",
    "            # check if calssification value is more common then other classification values\n",
    "            if list(targetColumn).count(value) > maxClass:\n",
    "                maxClass = list(targetColumn).count(value)\n",
    "                classification = value\n",
    "\n",
    "        return classification\n",
    "\n",
    "    def id3(self):\n",
    "        # base cases:\n",
    "        # 1) all instances have same target value -> leaf node with target value\n",
    "        if (self.data[self.target].nunique() == 1):\n",
    "            self.node.setClassification(self.data[self.target].iloc[0])\n",
    "            print(\"basecase1\")\n",
    "            return \n",
    "        # 2) out of discriptive features -> leaf node with majority of target values\n",
    "        if (not self.attributes):\n",
    "            self.node.setClassification(self.classify())\n",
    "            print(\"basecase2\")\n",
    "            return\n",
    "        # 3) no instances left in dataset -> take majority of parent node\n",
    "        if (self.data is None):\n",
    "            parent = self.node.getParent()\n",
    "            self.node.setClassification(parent.getClassification())\n",
    "            print(\"basecase3\")\n",
    "            return\n",
    "        # 4) maximal recursion depth:\n",
    "        if self.recursion_depth == self.max_recursion:\n",
    "            self.node.setClassification(self.classify())\n",
    "            print(\"basecase4\")\n",
    "            return\n",
    "\n",
    "\n",
    "        # recursive case:\n",
    "        # choose attribute with highest explainatory power\n",
    "        print(\"in recursion\")\n",
    "        print(\"attributs: \", self.attributes)\n",
    "        attribute = self.chooseAttribute()\n",
    "        self.node.setAttribute(attribute)\n",
    "        self.node.setClassification(self.classify())\n",
    "\n",
    "        # split data according to attribute\n",
    "        attributeColumn = self.data.loc[:, attribute]\n",
    "        values = set(attributeColumn)\n",
    "        new_attributes = self.attributes\n",
    "        new_attributes.remove(attribute)\n",
    "        recursion_depth = self.recursion_depth + 1\n",
    "\n",
    "        valueIsContinuous=False\n",
    "        \n",
    "        # chosen attribute is a continuous variable:\n",
    "        if self.is_continuous(values):\n",
    "            print(\"continuous\")\n",
    "            \n",
    "            targetColumn = self.data[self.target]\n",
    "            boundaries = self.getBoundaries(targetColumn, attributeColumn)\n",
    "            attributeColumn = self.replaceContinuous(boundaries, attributeColumn)\n",
    "            values = set(attributeColumn)\n",
    "            valueIsContinuous=True\n",
    "        \n",
    "        # create leaf node for each attribute value\n",
    "        for value in values:\n",
    "            subsetData = self.data[attributeColumn == value]\n",
    "            childNode = Node(parent=self.node, value=value, valueIsContinuous=valueIsContinuous, target=self.target)\n",
    "            self.node.setChild(childNode)\n",
    "            subset = train_data(data=subsetData, target=self.target, attributes=new_attributes, node=childNode, recursion_depth=recursion_depth)\n",
    "\n",
    "            # recursive call on all partitions\n",
    "            subset.id3()\n",
    "            \n",
    "\n",
    "    def retrain(self, data):\n",
    "        self.data = data\n",
    "        self.id3()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8fc2ed",
   "metadata": {},
   "source": [
    "### test_data Class\n",
    "\n",
    "to classify datapoints and test accuracy of tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "410057a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_data:\n",
    "    \n",
    "    def __init__(self, testData, target, node:Node):\n",
    "        self.testData = testData\n",
    "        self.target = target\n",
    "        self.node = node\n",
    "\n",
    "        # check whether node is trained:\n",
    "        if node.getAttribute() is None:\n",
    "            raise TypeError(\"node has to be part of a trained Decisiontree\")\n",
    "\n",
    "\n",
    "    def calcError(self, datapoint):\n",
    "\n",
    "        # compare leaf node classification and datapoint classification (basecase)\n",
    "        if self.node.isLeaf() == False:\n",
    "            return self.node.getClassification() == datapoint[self.target]\n",
    "\n",
    "        # traverse down the tree with the decision nodes (recursive case)\n",
    "        else:\n",
    "            attribute = self.node.getAttribute()\n",
    "            dataValue = datapoint[attribute]\n",
    "            for child in self.node.children:\n",
    "                # for interval values\n",
    "                if child.valueIsContinuous:\n",
    "                    if dataValue >= child.getValue()[0] and dataValue < child.getValue()[1]:\n",
    "                        return test_data(datapoint, self.target, child).calcError()\n",
    "                # for discrete values\n",
    "                if child.getValue() is dataValue:\n",
    "                    return test_data(datapoint, self.target, child).calcError()\n",
    "        \n",
    "        # if there are no children with the right value at decision node, use current classification (base case)\n",
    "        return self.node.getClassification() == self.target\n",
    "\n",
    "    \n",
    "    def calcClassification(self, datapoint):\n",
    "        \n",
    "        # get leaf node classification (basecase)\n",
    "        if self.node.isLeaf() == False:\n",
    "            return self.node.getClassification()\n",
    "\n",
    "        # traverse down the tree with the decision nodes (recursive case)\n",
    "        else:\n",
    "            attribute = self.node.getAttribute()\n",
    "            dataValue = datapoint[attribute]\n",
    "            for child in self.node.children:\n",
    "                # for interval values\n",
    "                if child.valueIsContinuous:\n",
    "                    if dataValue >= child.getValue()[0] and dataValue < child.getValue()[1]:\n",
    "                        return test_data(datapoint, self.target, child).calcClassification()\n",
    "                # for discrete values\n",
    "                if child.getValue() is dataValue:\n",
    "                    return test_data(datapoint, self.target, child).calcClassification()\n",
    "        \n",
    "        # if there are no children with the right value at decision node, get current classification (base case)\n",
    "        return self.node.getClassification()\n",
    "        \n",
    "    def classify(self):\n",
    "        classificationArray = []\n",
    "        for i in range(self.testData.shape[0]):\n",
    "            datapoint = self.testData.loc[i]\n",
    "            classificationArray.append(self.calcClassification(datapoint))\n",
    "        \n",
    "        return classificationArray\n",
    "    \n",
    "    def accuracy(self):\n",
    "        errorArray = []\n",
    "        for i in range(self.testData.shape[0]):\n",
    "            datapoint = self.testData.loc[i]\n",
    "            errorArray.append(self.calcError(datapoint))\n",
    "        \n",
    "        return np.mean(errorArray)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43d939c",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd065d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in recursion\n",
      "attributs:  ['gender', 'coxi', 'green']\n",
      "--------------------------------------------------------------------------\n",
      "gender is continuous and has 2 values: False\n",
      "size proportion: 0.5\n",
      "for value  f  in  0    f\n",
      "1    f\n",
      "2    f\n",
      "3    f\n",
      "4    f\n",
      "5    m\n",
      "6    m\n",
      "7    m\n",
      "8    m\n",
      "9    m\n",
      "Name: gender, dtype: object\n",
      "size proportion: 0.5\n",
      "for value  m  in  0    f\n",
      "1    f\n",
      "2    f\n",
      "3    f\n",
      "4    f\n",
      "5    m\n",
      "6    m\n",
      "7    m\n",
      "8    m\n",
      "9    m\n",
      "Name: gender, dtype: object\n",
      "--------------------------------------------------------------------------\n",
      "coxi is continuous and has 2 values: False\n",
      "size proportion: 0.4\n",
      "for value  False  in  0     True\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "5     True\n",
      "6     True\n",
      "7    False\n",
      "8    False\n",
      "9    False\n",
      "Name: coxi, dtype: bool\n",
      "size proportion: 0.6\n",
      "for value  True  in  0     True\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "5     True\n",
      "6     True\n",
      "7    False\n",
      "8    False\n",
      "9    False\n",
      "Name: coxi, dtype: bool\n",
      "--------------------------------------------------------------------------\n",
      "green is continuous and has 2 values: False\n",
      "size proportion: 0.4\n",
      "for value  False  in  0     True\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4    False\n",
      "5     True\n",
      "6    False\n",
      "7     True\n",
      "8    False\n",
      "9     True\n",
      "Name: green, dtype: bool\n",
      "size proportion: 0.6\n",
      "for value  True  in  0     True\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4    False\n",
      "5     True\n",
      "6    False\n",
      "7     True\n",
      "8    False\n",
      "9     True\n",
      "Name: green, dtype: bool\n",
      "basecase1\n",
      "in recursion\n",
      "attributs:  ['gender', 'coxi']\n",
      "--------------------------------------------------------------------------\n",
      "gender is continuous and has 2 values: False\n",
      "size proportion: 0.5\n",
      "for value  f  in  0    f\n",
      "1    f\n",
      "2    f\n",
      "5    m\n",
      "7    m\n",
      "9    m\n",
      "Name: gender, dtype: object\n",
      "size proportion: 0.5\n",
      "for value  m  in  0    f\n",
      "1    f\n",
      "2    f\n",
      "5    m\n",
      "7    m\n",
      "9    m\n",
      "Name: gender, dtype: object\n",
      "--------------------------------------------------------------------------\n",
      "coxi is continuous and has 2 values: False\n",
      "size proportion: 0.3333333333333333\n",
      "for value  False  in  0     True\n",
      "1     True\n",
      "2     True\n",
      "5     True\n",
      "7    False\n",
      "9    False\n",
      "Name: coxi, dtype: bool\n",
      "size proportion: 0.6666666666666666\n",
      "for value  True  in  0     True\n",
      "1     True\n",
      "2     True\n",
      "5     True\n",
      "7    False\n",
      "9    False\n",
      "Name: coxi, dtype: bool\n",
      "basecase1\n",
      "basecase1\n",
      " green :  False\n",
      "     classification:  vegan  =  False\n",
      " green :  True\n",
      "     coxi :  False\n",
      "         classification:  vegan  =  False\n",
      "     coxi :  True\n",
      "         classification:  vegan  =  True\n"
     ]
    }
   ],
   "source": [
    "d= {\"gender\": [\"f\", \"f\", \"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"m\", \"m\"],\n",
    "                   \"vegan\": [True, True, True, False, False, True, False, False, False, False],\n",
    "                   \"coxi\": [True, True, True, False, True, True, True, False, False, False],\n",
    "                   \"green\": [True, True, True, False, False, True, False, True, False, True]}\n",
    "\n",
    "data = pd.DataFrame(data = d)\n",
    "\n",
    "target = \"vegan\"\n",
    "attributes = list(data.columns)\n",
    "attributes.remove(target)\n",
    "\n",
    "rootNode = Node()\n",
    "\n",
    "decisionTree = train_data(data=data, target=target, attributes=attributes, node=rootNode, recursion_depth=5)\n",
    "decisionTree.id3()\n",
    "\n",
    "rootNode.printTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c77b385a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.6666666666666666\n",
      "classifications:  [False, False, False]\n"
     ]
    }
   ],
   "source": [
    "datapoints = {\"gender\": [\"f\", \"m\", \"m\"],\n",
    "                \"vegan\": [True, False, False],\n",
    "                \"coxi\": [False, False, False],\n",
    "                \"green\": [False, False, True]}\n",
    "\n",
    "datapoints = pd.DataFrame(data = datapoints)\n",
    "\n",
    "print(\"accuracy: \", test_data(datapoints, \"vegan\", rootNode).accuracy() )\n",
    "print(\"classifications: \", test_data(datapoints, \"vegan\", rootNode).classify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4e31b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in recursion\n",
      "attributs:  ['Type 1', 'Type 2', 'Total', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Legendary']\n",
      "--------------------------------------------------------------------------\n",
      "Type 1 is continuous and has 18 values: False\n",
      "size proportion: 0.0319001386962552\n",
      "for value  Ghost  in  0        Grass\n",
      "1        Grass\n",
      "2        Grass\n",
      "3         Fire\n",
      "4         Fire\n",
      "        ...   \n",
      "716       Dark\n",
      "717     Dragon\n",
      "718       Rock\n",
      "719    Psychic\n",
      "720       Fire\n",
      "Name: Type 1, Length: 721, dtype: object\n",
      "size proportion: 0.09153952843273232\n",
      "for value  Grass  in  0        Grass\n",
      "1        Grass\n",
      "2        Grass\n",
      "3         Fire\n",
      "4         Fire\n",
      "        ...   \n",
      "716       Dark\n",
      "717     Dragon\n",
      "718       Rock\n",
      "719    Psychic\n",
      "720       Fire\n",
      "Name: Type 1, Length: 721, dtype: object\n",
      "size proportion: 0.056865464632454926\n",
      "for value  Rock  in  0        Grass\n",
      "1        Grass\n",
      "2        Grass\n",
      "3         Fire\n",
      "4         Fire\n",
      "        ...   \n",
      "716       Dark\n",
      "717     Dragon\n",
      "718       Rock\n",
      "719    Psychic\n",
      "720       Fire\n",
      "Name: Type 1, Length: 721, dtype: object\n",
      "size proportion: 0.03467406380027739\n",
      "for value  Fighting  in  0        Grass\n",
      "1        Grass\n",
      "2        Grass\n",
      "3         Fire\n",
      "4         Fire\n",
      "        ...   \n",
      "716       Dark\n",
      "717     Dragon\n",
      "718       Rock\n",
      "719    Psychic\n",
      "720       Fire\n",
      "Name: Type 1, Length: 721, dtype: object\n",
      "size proportion: 0.0651872399445215\n",
      "for value  Psychic  in  0        Grass\n",
      "1        Grass\n",
      "2        Grass\n",
      "3         Fire\n",
      "4         Fire\n",
      "        ...   \n",
      "716       Dark\n",
      "717     Dragon\n",
      "718       Rock\n",
      "719    Psychic\n",
      "720       Fire\n",
      "Name: Type 1, Length: 721, dtype: object\n",
      "size proportion: 0.004160887656033287\n",
      "for value  Flying  in  0        Grass\n",
      "1        Grass\n",
      "2        Grass\n",
      "3         Fire\n",
      "4         Fire\n",
      "        ...   \n",
      "716       Dark\n",
      "717     Dragon\n",
      "718       Rock\n",
      "719    Psychic\n",
      "720       Fire\n",
      "Name: Type 1, Length: 721, dtype: object\n",
      "size proportion: 0.14563106796116504\n",
      "for value  Water  in  0        Grass\n",
      "1        Grass\n",
      "2        Grass\n",
      "3         Fire\n",
      "4         Fire\n",
      "        ...   \n",
      "716       Dark\n",
      "717     Dragon\n",
      "718       Rock\n",
      "719    Psychic\n",
      "720       Fire\n",
      "Name: Type 1, Length: 721, dtype: object\n",
      "size proportion: 0.023578363384188627\n",
      "for value  Fairy  in  0        Grass\n",
      "1        Grass\n",
      "2        Grass\n",
      "3         Fire\n",
      "4         Fire\n",
      "        ...   \n",
      "716       Dark\n",
      "717     Dragon\n",
      "718       Rock\n",
      "719    Psychic\n",
      "720       Fire\n",
      "Name: Type 1, Length: 721, dtype: object\n",
      "size proportion: 0.030513176144244106\n",
      "for value  Steel  in  0        Grass\n",
      "1        Grass\n",
      "2        Grass\n",
      "3         Fire\n",
      "4         Fire\n",
      "        ...   \n",
      "716       Dark\n",
      "717     Dragon\n",
      "718       Rock\n",
      "719    Psychic\n",
      "720       Fire\n",
      "Name: Type 1, Length: 721, dtype: object\n",
      "size proportion: 0.0651872399445215\n",
      "for value  Fire  in  0        Grass\n",
      "1        Grass\n",
      "2        Grass\n",
      "3         Fire\n",
      "4         Fire\n",
      "        ...   \n",
      "716       Dark\n",
      "717     Dragon\n",
      "718       Rock\n",
      "719    Psychic\n",
      "720       Fire\n",
      "Name: Type 1, Length: 721, dtype: object\n",
      "size proportion: 0.038834951456310676\n",
      "for value  Poison  in  0        Grass\n",
      "1        Grass\n",
      "2        Grass\n",
      "3         Fire\n",
      "4         Fire\n",
      "        ...   \n",
      "716       Dark\n",
      "717     Dragon\n",
      "718       Rock\n",
      "719    Psychic\n",
      "720       Fire\n",
      "Name: Type 1, Length: 721, dtype: object\n",
      "size proportion: 0.033287101248266296\n",
      "for value  Dragon  in  0        Grass\n",
      "1        Grass\n",
      "2        Grass\n",
      "3         Fire\n",
      "4         Fire\n",
      "        ...   \n",
      "716       Dark\n",
      "717     Dragon\n",
      "718       Rock\n",
      "719    Psychic\n",
      "720       Fire\n",
      "Name: Type 1, Length: 721, dtype: object\n",
      "size proportion: 0.0319001386962552\n",
      "for value  Ice  in  0        Grass\n",
      "1        Grass\n",
      "2        Grass\n",
      "3         Fire\n",
      "4         Fire\n",
      "        ...   \n",
      "716       Dark\n",
      "717     Dragon\n",
      "718       Rock\n",
      "719    Psychic\n",
      "720       Fire\n",
      "Name: Type 1, Length: 721, dtype: object\n",
      "size proportion: 0.08737864077669903\n",
      "for value  Bug  in  0        Grass\n",
      "1        Grass\n",
      "2        Grass\n",
      "3         Fire\n",
      "4         Fire\n",
      "        ...   \n",
      "716       Dark\n",
      "717     Dragon\n",
      "718       Rock\n",
      "719    Psychic\n",
      "720       Fire\n",
      "Name: Type 1, Length: 721, dtype: object\n",
      "size proportion: 0.049930651872399444\n",
      "for value  Electric  in  0        Grass\n",
      "1        Grass\n",
      "2        Grass\n",
      "3         Fire\n",
      "4         Fire\n",
      "        ...   \n",
      "716       Dark\n",
      "717     Dragon\n",
      "718       Rock\n",
      "719    Psychic\n",
      "720       Fire\n",
      "Name: Type 1, Length: 721, dtype: object\n",
      "size proportion: 0.1289875173370319\n",
      "for value  Normal  in  0        Grass\n",
      "1        Grass\n",
      "2        Grass\n",
      "3         Fire\n",
      "4         Fire\n",
      "        ...   \n",
      "716       Dark\n",
      "717     Dragon\n",
      "718       Rock\n",
      "719    Psychic\n",
      "720       Fire\n",
      "Name: Type 1, Length: 721, dtype: object\n",
      "size proportion: 0.038834951456310676\n",
      "for value  Dark  in  0        Grass\n",
      "1        Grass\n",
      "2        Grass\n",
      "3         Fire\n",
      "4         Fire\n",
      "        ...   \n",
      "716       Dark\n",
      "717     Dragon\n",
      "718       Rock\n",
      "719    Psychic\n",
      "720       Fire\n",
      "Name: Type 1, Length: 721, dtype: object\n",
      "size proportion: 0.04160887656033287\n",
      "for value  Ground  in  0        Grass\n",
      "1        Grass\n",
      "2        Grass\n",
      "3         Fire\n",
      "4         Fire\n",
      "        ...   \n",
      "716       Dark\n",
      "717     Dragon\n",
      "718       Rock\n",
      "719    Psychic\n",
      "720       Fire\n",
      "Name: Type 1, Length: 721, dtype: object\n",
      "--------------------------------------------------------------------------\n",
      "Type 2 is continuous and has 19 values: False\n",
      "size proportion: 0.019417475728155338\n",
      "for value  Rock  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "size proportion: 0.024965325936199722\n",
      "for value  Fairy  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "size proportion: 0.012482662968099861\n",
      "for value  Fire  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "size proportion: 0.008321775312066574\n",
      "for value  Electric  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "size proportion: 0.022191400832177532\n",
      "for value  Dark  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "size proportion: 0.024965325936199722\n",
      "for value  Grass  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "size proportion: 0.03744798890429958\n",
      "for value  Psychic  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "size proportion: 0.026352288488210817\n",
      "for value  Steel  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "size proportion: 0.019417475728155338\n",
      "for value  Dragon  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "size proportion: 0.026352288488210817\n",
      "for value  Fighting  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "size proportion: 0.004160887656033287\n",
      "for value  Bug  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "size proportion: 0.005547850208044383\n",
      "for value  Normal  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "size proportion: 0.04160887656033287\n",
      "for value  Ground  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "size proportion: 0.016643550624133148\n",
      "for value  Ghost  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "size proportion: 0.12066574202496533\n",
      "for value  Flying  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "size proportion: 0.018030513176144243\n",
      "for value  Water  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "size proportion: 0.0\n",
      "for value  nan  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "size proportion: 0.04299583911234397\n",
      "for value  Poison  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "size proportion: 0.013869625520110958\n",
      "for value  Ice  in  0      Poison\n",
      "1      Poison\n",
      "2      Poison\n",
      "3         NaN\n",
      "4         NaN\n",
      "        ...  \n",
      "716    Flying\n",
      "717    Ground\n",
      "718     Fairy\n",
      "719     Ghost\n",
      "720     Water\n",
      "Name: Type 2, Length: 721, dtype: object\n",
      "--------------------------------------------------------------------------\n",
      "Total is continuous and has 183 values: True\n",
      "\n",
      "replaced values of Total by intervals: \n",
      "{(-inf, 234.0), (342.0, 396.0), (612.0, 666.0), (396.0, 450.0), (666.0, inf), (450.0, 504.0), (234.0, 288.0), (504.0, 558.0), (288.0, 342.0), (558.0, 612.0)}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erna\\AppData\\Local\\Temp\\ipykernel_13788\\2599903142.py:164: RuntimeWarning: divide by zero encountered in log\n",
      "  splitInfo = splitInfo + (- s * np.log(s))\n",
      "C:\\Users\\erna\\AppData\\Local\\Temp\\ipykernel_13788\\2599903142.py:164: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  splitInfo = splitInfo + (- s * np.log(s))\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\scipy\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\scipy\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\scipy\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: False",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m rootNode \u001b[38;5;241m=\u001b[39m Node()\n\u001b[0;32m     14\u001b[0m decisionTree \u001b[38;5;241m=\u001b[39m train_data(data\u001b[38;5;241m=\u001b[39mdata, target\u001b[38;5;241m=\u001b[39mtarget, attributes\u001b[38;5;241m=\u001b[39mattributes, node\u001b[38;5;241m=\u001b[39mrootNode, recursion_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mdecisionTree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid3\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m rootNode\u001b[38;5;241m.\u001b[39mprintTree()\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mtrain_data.id3\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min recursion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributs: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattributes)\n\u001b[1;32m--> 257\u001b[0m attribute \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchooseAttribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39msetAttribute(attribute)\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39msetClassification(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassify())\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mtrain_data.chooseAttribute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)                \n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# calculate gainRatio\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m gain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgainRatio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattributeColumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# store attribute with highest information gain\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gain \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m maxGain:\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mtrain_data.gainRatio\u001b[1;34m(self, attributeColumn, values)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgainRatio\u001b[39m(\u001b[38;5;28mself\u001b[39m, attributeColumn, values):\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# calculating the Gain Ratio instead of the InforamtionGain\u001b[39;00m\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# to prefer attributes with few values\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m     infoGain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minformationGain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattributeColumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     splitInfo \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m values:\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mtrain_data.informationGain\u001b[1;34m(self, attributeColumn, values)\u001b[0m\n\u001b[0;32m    137\u001b[0m gainSum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m values:\n\u001b[1;32m--> 141\u001b[0m     subsetData \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mattributeColumn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    142\u001b[0m     subset \u001b[38;5;241m=\u001b[39m train_data(subsetData, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattributes)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m# claculate entropy and normalize by size of subsets\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\scipy\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\scipy\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: False"
     ]
    }
   ],
   "source": [
    "# 1. load data\n",
    "data = pd.read_csv(\"data/pokemon_no_duplicates.csv\")\n",
    "\n",
    "# 2. prepare data\n",
    "#data = prepare_data(data)\n",
    "\n",
    "# choose the target value\n",
    "data = data.drop(columns=[\"Name\", \"#\"])\n",
    "target = \"Generation\"\n",
    "attributes = list(data.columns)\n",
    "attributes.remove(target)\n",
    "# 3. split_data with id3\n",
    "rootNode = Node()\n",
    "decisionTree = train_data(data=data, target=target, attributes=attributes, node=rootNode, recursion_depth=0)\n",
    "decisionTree.id3()\n",
    "\n",
    "rootNode.printTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499951aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#datapoints = data.loc(5) #error\n",
    "\n",
    "#print(\"accuracy: \", test_data(datapoints, \"Generation\", rootNode).accuracy() )\n",
    "#print(\"classifications: \", test_data(datapoints, \"Generation\", rootNode).classify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6764686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBoundaries(tColumn, aColumn):\n",
    "        # by looking at the target column and the attribute column the\n",
    "        # function decides on deciosion boundaries in a continuous varibale, where classification changes\n",
    "        \n",
    "        # 1) sort the two columns\n",
    "        columns = pd.DataFrame(data={\"a\":list(aColumn), \"t\":list(tColumn)}).sort_values(by=\"a\")\n",
    "        columns.index = range(len(columns))\n",
    "\n",
    "        # 2) find decision boundaries where classification changes\n",
    "        leftBound = np.NINF\n",
    "        rightBound = None\n",
    "        boundaries = []\n",
    "        currentClass = columns[\"t\"][0]\n",
    "        for i in range(len(columns)):\n",
    "            # when classification changes\n",
    "            if(columns[\"t\"][i] != currentClass):\n",
    "                currentClass = columns[\"t\"][i]\n",
    "                \n",
    "                # get the value in the middel\n",
    "                beforeSwitch = columns[\"a\"][i-1]\n",
    "                afterSwitch = columns[\"a\"][i]\n",
    "                rightBound = (beforeSwitch + afterSwitch) / 2\n",
    "\n",
    "                # safe the tupple of two boundaries with a uniform classification\n",
    "                boundaries.append((leftBound, rightBound))\n",
    "                leftBound = rightBound\n",
    "        \n",
    "        # last tupple that does not get triggerd by a switch of classification\n",
    "        boundaries.append((leftBound, np.PINF))\n",
    "        \n",
    "        return columns, boundaries\n",
    "\n",
    "\n",
    "aColumn = pd.Series([1, 12, 4, 5.5, 6, 10, 15])\n",
    "tColumn = pd.Series([\"a\", \"c\", \"b\", \"a\", \"a\", \"c\", \"c\"])\n",
    "columns, boundaries = getBoundaries(tColumn, aColumn)\n",
    "print(\"column of classification sorted by attribute: \\n\", columns)\n",
    "print(\"boundary tupples: \", boundaries)\n",
    "\n",
    "def replaceContinuous(boundaries, aColumn):\n",
    "        # replaces the continuous values of an attribute by the\n",
    "        # tuples that represent an interval\n",
    "        \n",
    "        newAColumn = []\n",
    "        for value in aColumn:\n",
    "            for l, r in boundaries:\n",
    "                if value > l and value < r:\n",
    "                    newAColumn.append((l, r))\n",
    "        return newAColumn\n",
    "            \n",
    "        '''for i in range(len(boundaries)):\n",
    "            # get left and right boundary of interval\n",
    "            l = boundaries[i][0]\n",
    "            r = boundaries[i][1]\n",
    "            print(f\"{l}, {r}\")\n",
    "            # replac any value of column that fits the interval by the interval\n",
    "            for value in newAColumn:\n",
    "                \n",
    "                    print(f\"{value} is in interval {boundaries[i]}\")\n",
    "                    value = boundaries[i]\n",
    "                    print(\"new value: \", value)\n",
    "            print(newAColumn)\n",
    "        return pd.Series(newAColumn)'''\n",
    "print(aColumn)\n",
    "print(replaceContinuous(boundaries, aColumn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f546a3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setBoundaries(aColumn):\n",
    "        \n",
    "        maximum = np.max(aColumn)\n",
    "        minimum = np.min(aColumn)\n",
    "        stepsize = (maximum - minimum)/ 10\n",
    "        boundaries = []\n",
    "        \n",
    "        leftBound = np.NINF\n",
    "        rightBound = minimum + stepsize\n",
    "        for i in range(9):\n",
    "            boundaries.append((leftBound, rightBound))\n",
    "            leftBound = rightBound\n",
    "            rightBound = leftBound + stepsize\n",
    "        boundaries.append((leftBound, np.PINF))\n",
    "        \n",
    "        return boundaries\n",
    "setBoundaries([3,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2610ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
