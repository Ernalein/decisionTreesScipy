{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f2db3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b597fe8",
   "metadata": {},
   "source": [
    "### Node Class\n",
    "\n",
    "Tree structure is build by Node Objects. Each node object has an attribute and a classification when trained, as well as a parent node and the value associated with the parents attribute and a classification.\n",
    "The nodes are trained by tran_data and also offer the printTree function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74740ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    '''\n",
    "    class Node innitialises a tree structure for a non-binary tree\n",
    "    it has the typical setter and getter methods and a method to remove a \n",
    "    child from the list of children\n",
    "    '''\n",
    "    def __init__(self, parent = None, attribute = None, classification = None, value = None, target = None):\n",
    "        self.children = []  \n",
    "        self.parent = parent\n",
    "        self.attribute = attribute\n",
    "        self.classification = classification\n",
    "        self.value = value\n",
    "        self.target = target\n",
    "        \n",
    "\n",
    "    def setChild(self, node):\n",
    "        self.children.append(node)\n",
    "        \n",
    "    def setParent(self, node):\n",
    "        if (self.parent is not None):\n",
    "            self.parent.children.remove(self)\n",
    "        self.parent = node\n",
    "\n",
    "    def getChildren(self):\n",
    "        return self.children\n",
    "    \n",
    "    def getParent(self):\n",
    "        return self.parent\n",
    "    \n",
    "    def deleteChild(self, node):\n",
    "        if (node in self.children):\n",
    "            node.parent = None\n",
    "            self.children.remove(node)\n",
    "        else:\n",
    "            raise TypeError(\"Child not in Children\")\n",
    "        \n",
    "    def isLeaf(self):\n",
    "        if len(self.children) > 0:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def isRoot(self):\n",
    "        if (self.parent is None):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def setAttribute(self, attribute):\n",
    "        self.attribute = attribute\n",
    "    \n",
    "    def getAttribute(self):\n",
    "        return self.attribute\n",
    "    \n",
    "    def setClassification(self, classification):\n",
    "        self.classification = classification\n",
    "    \n",
    "    def getClassification(self):\n",
    "        return self.classification\n",
    "    \n",
    "    def setValue(self,value):\n",
    "        self.value = value\n",
    "\n",
    "    def getValue(self):\n",
    "        return self.value\n",
    "    \n",
    "\n",
    "    def printTree(self, level = 0):\n",
    "        tab = \"    \"\n",
    "        if self.isLeaf():\n",
    "            print(tab*level, \"classification: \", self.target, \" = \" , self.classification)\n",
    "        else:\n",
    "            for child in self.children:\n",
    "                print(tab*level, self.attribute, \": \", child.value)\n",
    "                child.printTree(level + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ede2ff",
   "metadata": {},
   "source": [
    "### train_Data Class\n",
    "\n",
    "The class represents a data (sub)set that is used to train the (sub)tree. It has a (root) node which it is responsible to train (choose attribute, classification, and child nodes) via the id3 function.\n",
    "I can also deal with continuous variables by ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fb88b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_data:\n",
    "    '''\n",
    "    class train_data has all important functions for ID3 Algorithm:\n",
    "    it can calculate the entropy of some data, the information gain, choose an attriute.\n",
    "    within the ID3 algorithm a tree will be trained.\n",
    "    the function retrain(data) retrains a trained tree with new data.\n",
    "    '''\n",
    "    def __init__(self, data, target, attributes, node:Node = None, recursion_depth = None, continuous_splitting = 0.1,  max_recursion = 10):\n",
    "        \n",
    "        self.data = data\n",
    "        if not isinstance(self.data, pd.DataFrame):\n",
    "            raise TypeError(\"Data has to be a Pandas Dataframe\")\n",
    "        \n",
    "        self.target = target\n",
    "        if not isinstance(self.target, str):\n",
    "            raise TypeError(\"Taget has to be of type string\")\n",
    "        \n",
    "        self.attributes = attributes\n",
    "        if not isinstance(attributes, list):\n",
    "            raise TypeError(\"Attributes have to have structure list\")\n",
    "            \n",
    "        for attribute in self.attributes:\n",
    "            if not isinstance(attribute, str):\n",
    "                raise TypeError(\"Attributes have to be of type string\")\n",
    "\n",
    "        self.node = node\n",
    "        self.continuous_splitting = continuous_splitting\n",
    "        self.recursion_depth = recursion_depth\n",
    "        self.max_recursion = max_recursion\n",
    "    \n",
    "    def is_continuous(self, values):\n",
    "        # checks is variable is a continuous variable\n",
    "        if len(values) > 10:\n",
    "            for value in values:\n",
    "                if value is not int or float:\n",
    "                    return False\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def attribute_continuous(self, attributeColumn, values):\n",
    "        \n",
    "        # sort the set\n",
    "        values = list(sorted(values))\n",
    "        split_lenght = int(len(values) * self.continuous_splitting)\n",
    "        maxGain = 0\n",
    "        maxValue = 0\n",
    "        for split in range(split_lenght):\n",
    "            value = values[split]\n",
    "\n",
    "            subsetData1 = self.data[attributeColumn <= value]\n",
    "            subsetData2 = self.data[attributeColumn > value]\n",
    "            subset1 = train_data(subsetData1, self.target, self.attributes)\n",
    "            subset2 = train_data(subsetData2, self.target, self.attributes)\n",
    "\n",
    "            gainSum =  (subsetData1.shape[0] / self.data.shape[0]) * subset1.entropy() + (subsetData2.shape[0] / self.data.shape[0]) * subset2.entropy()\n",
    "            infoGain = self.data.entropy() - gainSum\n",
    "\n",
    "            if infoGain > maxGain:\n",
    "                maxGain = infoGain\n",
    "                maxValue = value\n",
    "        \n",
    "        return [maxGain, maxValue]\n",
    "\n",
    "    def entropy(self):\n",
    "        targetColumn = self.data.loc[:, self.target]\n",
    "\n",
    "        values = set(targetColumn)\n",
    "        entropySum = 0\n",
    "        for value in values:\n",
    "            p = list(targetColumn).count(value) / len(targetColumn)\n",
    "            entropySum = entropySum + (- p * np.log(p))\n",
    "\n",
    "        return entropySum\n",
    "    \n",
    "\n",
    "    def informationGain(self, attributeColumn, values):\n",
    "        gainSum = 0\n",
    "        \n",
    "        for value in values:\n",
    "            \n",
    "            subsetData = self.data[attributeColumn == value]\n",
    "            subset = train_data(subsetData, self.target, self.attributes)\n",
    "            # claculate entropy and normalize by size of subsets\n",
    "            gainSum = gainSum + (subsetData.shape[0] / self.data.shape[0]) * subset.entropy()\n",
    "\n",
    "        # substract summed and weighted entropy of subsets from entropy of whole set    \n",
    "        infoGain = self.entropy() - gainSum\n",
    "\n",
    "        return infoGain\n",
    "\n",
    "\n",
    "    def chooseAttribute(self):\n",
    "        maxGain= 0\n",
    "        maxAttribute = \"\"\n",
    "\n",
    "        # calculate Information Gain for each attribute\n",
    "        for attribute in self.attributes:\n",
    "            attributeColumn = self.data.loc[:, attribute]\n",
    "            values = set(attributeColumn)\n",
    "            gain = 0\n",
    "\n",
    "            # calculate Information gain for this attribute\n",
    "            if self.is_continuous(values):\n",
    "                gain = self.attribute_continuous(attributeColumn, values)[0] # calculates the split information ???\n",
    "            else:\n",
    "                gain = self.informationGain(attributeColumn, values)\n",
    "\n",
    "            # store attribute with highest information gain\n",
    "            if gain >= maxGain:\n",
    "                maxGain = gain\n",
    "                maxAttribute = attribute\n",
    "\n",
    "        # choose attribute with highest Information Gain\n",
    "        return maxAttribute\n",
    "\n",
    "    def classify(self):\n",
    "        # returns the most commen classification of the dataset\n",
    "        \n",
    "        targetColumn = self.data.loc[:, self.target]\n",
    "        values = set(targetColumn)\n",
    "        maxClass = 0  # highest number of values\n",
    "        classification = \"\" # classification of most common value\n",
    "        for value in values:\n",
    "            # check if calssification value is more common then other classification values\n",
    "            if list(targetColumn).count(value) > maxClass:\n",
    "                maxClass = list(targetColumn).count(value)\n",
    "                classification = value\n",
    "\n",
    "        return classification\n",
    "\n",
    "    def id3(self):\n",
    "        # base cases:\n",
    "        # 1) all instances have same target value -> leaf node with target value\n",
    "        if (self.data[self.target].nunique() == 1):\n",
    "            self.node.setClassification(self.data[self.target].iloc[0])\n",
    "            print(\"basecase1\")\n",
    "            return \n",
    "        # 2) out of discriptive features -> leaf node with majority of target values\n",
    "        if (not self.attributes):\n",
    "            self.node.setClassification(self.classify())\n",
    "            print(\"basecase2\")\n",
    "            return\n",
    "        # 3) no instances left in dataset -> take majority of parent node\n",
    "        if (self.data is None):\n",
    "            parent = self.node.getParent()\n",
    "            self.node.setClassification(parent.getClassification())\n",
    "            print(\"basecase3\")\n",
    "            return\n",
    "        # 4) maximal recursion depth:\n",
    "        if self.recursion_depth == self.max_recursion:\n",
    "            self.node.setClassification(self.classify())\n",
    "            print(\"basecase4\")\n",
    "            return\n",
    "\n",
    "\n",
    "        # recursive case:\n",
    "        # choose attribute with highest explainatory power\n",
    "        print(\"in recursion\")\n",
    "        print(\"attributs: \", self.attributes)\n",
    "        attribute = self.chooseAttribute()\n",
    "        self.node.setAttribute(attribute)\n",
    "        self.node.setClassification(self.classify())\n",
    "\n",
    "        # split data according to attribute\n",
    "        attributeColumn = self.data.loc[:, attribute]\n",
    "        values = set(attributeColumn)\n",
    "        new_attributes = self.attributes\n",
    "        new_attributes.remove(attribute)\n",
    "        recursion_depth = self.recursion_depth + 1\n",
    "\n",
    "        # chosen attribute is a continuous variable:\n",
    "        if self.is_continuous(values):\n",
    "            print(\"continuous\")\n",
    "            value = self.attribute_continuous(attributeColumn, values)[1]\n",
    "\n",
    "            subsetData1 = self.data[attributeColumn <= value]\n",
    "            subsetData2 = self.data[attributeColumn > value]\n",
    "            childNode1 = Node(parent=self.node, value=f\"<= {value}\")\n",
    "            childNode2 = Node(parent=self.node, value=f\"> {value}\")\n",
    "            self.node.setChild(childNode1)\n",
    "            self.node.setChild(childNode2)\n",
    "            \n",
    "            subset1 = train_data(data=subsetData1, target=self.target, attributes=new_attributes, node=childNode1, recursion_depth=recursion_depth)\n",
    "            subset2 = train_data(data=subsetData2, target=self.target, attributes=new_attributes, node=childNode2, recursion_depth=recursion_depth)\n",
    "            # recursive call on all partitions\n",
    "            subset1.id3()\n",
    "            subset2.id3()\n",
    "        \n",
    "        # chosen attribute is a categorical variable:\n",
    "        else:\n",
    "            print(\"not continuous\")\n",
    "            for value in values:\n",
    "                subsetData = self.data[attributeColumn == value]\n",
    "                childNode = Node(parent=self.node, value=value, target=self.target)\n",
    "                self.node.setChild(childNode)\n",
    "                subset = train_data(data=subsetData, target=self.target, attributes=new_attributes, node=childNode, recursion_depth=recursion_depth)\n",
    "    \n",
    "                # recursive call on all partitions\n",
    "                subset.id3()\n",
    "\n",
    "    def retrain(self, data):\n",
    "        self.data = data\n",
    "        self.id3()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4660f2",
   "metadata": {},
   "source": [
    "### test_data Class\n",
    "\n",
    "to classify datapoints and test accuracy of tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56f69e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_data:\n",
    "    \n",
    "    def __init__(self, testData, target, node:Node):\n",
    "        self.testData = testData\n",
    "        self.target = target\n",
    "        self.node = node\n",
    "\n",
    "        # check whether node is trained:\n",
    "        if node.getAttribute() is None:\n",
    "            raise TypeError(\"node has to be part of a trained Decisiontree\")\n",
    "\n",
    "\n",
    "    def calcError(self, datapoint):\n",
    "\n",
    "        # compare leaf node classification and datapoint classification (basecase)\n",
    "        if self.node.isLeaf() == False:\n",
    "            return self.node.getClassification() == datapoint[self.target]\n",
    "\n",
    "        # traverse down the tree with the decision nodes (recursive case)\n",
    "        else:\n",
    "            attribute = self.node.getAttribute()\n",
    "            dataValue = datapoint[attribute]\n",
    "            for child in self.node.children:\n",
    "                if child.getValue() is dataValue:\n",
    "                    return test_data(datapoint, self.target, child).calcError()\n",
    "        \n",
    "        # if there are no children with the right value at decision node, use current classification (base case)\n",
    "        return self.node.getClassification() == self.target\n",
    "\n",
    "    \n",
    "    def calcClassification(self, datapoint):\n",
    "        \n",
    "        # get leaf node classification (basecase)\n",
    "        if self.node.isLeaf() == False:\n",
    "            return self.node.getClassification()\n",
    "\n",
    "        # traverse down the tree with the decision nodes (recursive case)\n",
    "        else:\n",
    "            attribute = self.node.getAttribute()\n",
    "            dataValue = datapoint[attribute]\n",
    "            for child in self.node.children:\n",
    "                if child.getValue() is dataValue:\n",
    "                    return test_data(datapoint, self.target, child).calcClassification()\n",
    "        \n",
    "        # if there are no children with the right value at decision node, get current classification (base case)\n",
    "        return self.node.getClassification()\n",
    "        \n",
    "    def classify(self):\n",
    "        classificationArray = []\n",
    "        for i in range(self.testData.shape[0]):\n",
    "            datapoint = self.testData.loc[i]\n",
    "            classificationArray.append(self.calcClassification(datapoint))\n",
    "        \n",
    "        return classificationArray\n",
    "    \n",
    "    def accuracy(self):\n",
    "        errorArray = []\n",
    "        for i in range(self.testData.shape[0]):\n",
    "            datapoint = self.testData.loc[i]\n",
    "            errorArray.append(self.calcError(datapoint))\n",
    "        \n",
    "        return np.mean(errorArray)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28345bbd",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57eb9852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in recursion\n",
      "attributs:  ['gender', 'coxi', 'green']\n",
      "not continuous\n",
      "basecase1\n",
      "in recursion\n",
      "attributs:  ['gender', 'coxi']\n",
      "not continuous\n",
      "basecase1\n",
      "basecase1\n",
      " green :  False\n",
      "     classification:  vegan  =  False\n",
      " green :  True\n",
      "     coxi :  False\n",
      "         classification:  vegan  =  False\n",
      "     coxi :  True\n",
      "         classification:  vegan  =  True\n"
     ]
    }
   ],
   "source": [
    "d= {\"gender\": [\"f\", \"f\", \"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"m\", \"m\"],\n",
    "                   \"vegan\": [True, True, True, False, False, True, False, False, False, False],\n",
    "                   \"coxi\": [True, True, True, False, True, True, True, False, False, False],\n",
    "                   \"green\": [True, True, True, False, False, True, False, True, False, True]}\n",
    "\n",
    "data = pd.DataFrame(data = d)\n",
    "\n",
    "target = \"vegan\"\n",
    "attributes = list(data.columns)\n",
    "attributes.remove(target)\n",
    "\n",
    "rootNode = Node()\n",
    "\n",
    "decisionTree = train_data(data=data, target=target, attributes=attributes, node=rootNode, recursion_depth=5)\n",
    "decisionTree.id3()\n",
    "\n",
    "rootNode.printTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fd27ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.6666666666666666\n",
      "classifications:  [False, False, False]\n"
     ]
    }
   ],
   "source": [
    "datapoints = {\"gender\": [\"f\", \"m\", \"m\"],\n",
    "                \"vegan\": [True, False, False],\n",
    "                \"coxi\": [False, False, False],\n",
    "                \"green\": [False, False, True]}\n",
    "\n",
    "datapoints = pd.DataFrame(data = datapoints)\n",
    "\n",
    "print(\"accuracy: \", test_data(datapoints, \"vegan\", rootNode).accuracy() )\n",
    "print(\"classifications: \", test_data(datapoints, \"vegan\", rootNode).classify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d906403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in recursion\n",
      "attributs:  ['Type 1', 'Type 2', 'Total', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Legendary']\n",
      "not continuous\n",
      "in recursion\n",
      "attributs:  ['Type 1', 'Total', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Legendary']\n",
      "not continuous\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "in recursion\n",
      "attributs:  ['Type 1', 'Total', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Legendary']\n",
      "not continuous\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "in recursion\n",
      "attributs:  ['Type 1', 'Total', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Legendary']\n",
      "not continuous\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "in recursion\n",
      "attributs:  ['Type 1', 'Total', 'HP', 'Defense', 'Sp. Atk', 'Legendary']\n",
      "not continuous\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "in recursion\n",
      "attributs:  ['Type 1', 'Total', 'HP', 'Defense', 'Sp. Atk']\n",
      "not continuous\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "in recursion\n",
      "attributs:  ['Type 1', 'Total', 'HP', 'Defense']\n",
      "not continuous\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "in recursion\n",
      "attributs:  ['Type 1', 'Total', 'HP']\n",
      "not continuous\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "in recursion\n",
      "attributs:  ['Type 1', 'HP']\n",
      "not continuous\n",
      "basecase1\n",
      "basecase1\n",
      "in recursion\n",
      "attributs:  ['Type 1']\n",
      "not continuous\n",
      "basecase2\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase1\n",
      "basecase2\n",
      "basecase2\n",
      "basecase2\n",
      "basecase2\n",
      "basecase2\n",
      "basecase2\n",
      "basecase2\n",
      "basecase2\n",
      "basecase2\n",
      "basecase2\n",
      "basecase2\n",
      "basecase2\n",
      "basecase2\n",
      "basecase2\n",
      "basecase2\n",
      "basecase1\n",
      " Type 2 :  Grass\n",
      "     Speed :  100\n",
      "         classification:  Generation  =  2\n",
      "     Speed :  36\n",
      "         classification:  Generation  =  4\n",
      "     Speed :  70\n",
      "         classification:  Generation  =  3\n",
      "     Speed :  38\n",
      "         classification:  Generation  =  6\n",
      "     Speed :  42\n",
      "         classification:  Generation  =  5\n",
      "     Speed :  43\n",
      "         classification:  Generation  =  3\n",
      "     Speed :  75\n",
      "         classification:  Generation  =  5\n",
      "     Speed :  50\n",
      "         classification:  Generation  =  3\n",
      "     Speed :  51\n",
      "         classification:  Generation  =  6\n",
      "     Speed :  84\n",
      "         classification:  Generation  =  6\n",
      "     Speed :  23\n",
      "         classification:  Generation  =  3\n",
      "     Speed :  56\n",
      "         classification:  Generation  =  6\n",
      "     Speed :  25\n",
      "         classification:  Generation  =  1\n",
      "     Speed :  92\n",
      "         classification:  Generation  =  5\n",
      "     Speed :  30\n",
      "         Sp. Def :  80\n",
      "             classification:  Generation  =  1\n",
      "         Sp. Def :  50\n",
      "             classification:  Generation  =  3\n",
      "     Speed :  95\n",
      "         classification:  Generation  =  5\n",
      " Type 2 :  Steel\n",
      "     Attack :  130\n",
      "         classification:  Generation  =  2\n",
      "     Attack :  35\n",
      "         classification:  Generation  =  1\n",
      "     Attack :  70\n",
      "         classification:  Generation  =  4\n",
      "     Attack :  135\n",
      "         classification:  Generation  =  5\n",
      "     Attack :  42\n",
      "         classification:  Generation  =  4\n",
      "     Attack :  109\n",
      "         classification:  Generation  =  5\n",
      "     Attack :  110\n",
      "         classification:  Generation  =  4\n",
      "     Attack :  50\n",
      "         classification:  Generation  =  5\n",
      "     Attack :  52\n",
      "         classification:  Generation  =  4\n",
      "     Attack :  85\n",
      "         classification:  Generation  =  5\n",
      "     Attack :  86\n",
      "         classification:  Generation  =  4\n",
      "     Attack :  55\n",
      "         classification:  Generation  =  4\n",
      "     Attack :  120\n",
      "         classification:  Generation  =  5\n",
      "     Attack :  90\n",
      "         Legendary :  False\n",
      "             classification:  Generation  =  2\n",
      "         Legendary :  True\n",
      "             classification:  Generation  =  4\n",
      "     Attack :  60\n",
      "         classification:  Generation  =  1\n",
      "     Attack :  125\n",
      "         classification:  Generation  =  5\n",
      "     Attack :  94\n",
      "         classification:  Generation  =  5\n",
      " Type 2 :  Psychic\n",
      "     Sp. Atk :  128\n",
      "         classification:  Generation  =  5\n",
      "     Sp. Atk :  130\n",
      "         classification:  Generation  =  3\n",
      "     Sp. Atk :  24\n",
      "         classification:  Generation  =  4\n",
      "     Sp. Atk :  35\n",
      "         classification:  Generation  =  3\n",
      "     Sp. Atk :  37\n",
      "         classification:  Generation  =  6\n",
      "     Sp. Atk :  40\n",
      "         Defense :  65\n",
      "             classification:  Generation  =  1\n",
      "         Defense :  55\n",
      "             classification:  Generation  =  3\n",
      "     Sp. Atk :  55\n",
      "         classification:  Generation  =  3\n",
      "     Sp. Atk :  60\n",
      "         Total :  410\n",
      "             classification:  Generation  =  3\n",
      "         Total :  325\n",
      "             classification:  Generation  =  1\n",
      "     Sp. Atk :  68\n",
      "         classification:  Generation  =  6\n",
      "     Sp. Atk :  70\n",
      "         classification:  Generation  =  3\n",
      "     Sp. Atk :  79\n",
      "         classification:  Generation  =  4\n",
      "     Sp. Atk :  85\n",
      "         classification:  Generation  =  2\n",
      "     Sp. Atk :  90\n",
      "         classification:  Generation  =  2\n",
      "     Sp. Atk :  95\n",
      "         classification:  Generation  =  3\n",
      "     Sp. Atk :  100\n",
      "         HP :  100\n",
      "             classification:  Generation  =  3\n",
      "         HP :  60\n",
      "             classification:  Generation  =  1\n",
      "         HP :  95\n",
      "             Type 1 :  Water\n",
      "                 classification:  Generation  =  1\n",
      "     Sp. Atk :  110\n",
      "         classification:  Generation  =  3\n",
      "     Sp. Atk :  114\n",
      "         classification:  Generation  =  6\n",
      "     Sp. Atk :  115\n",
      "         classification:  Generation  =  1\n",
      "     Sp. Atk :  125\n",
      "         classification:  Generation  =  1\n",
      " Type 2 :  Poison\n",
      "     classification:  Generation  =  1\n",
      " Type 2 :  Bug\n",
      "     classification:  Generation  =  3\n",
      " Type 2 :  Fairy\n",
      "     classification:  Generation  =  3\n",
      " Type 2 :  Electric\n",
      "     classification:  Generation  =  5\n",
      " Type 2 :  Fire\n",
      "     classification:  Generation  =  5\n",
      " Type 2 :  Fighting\n",
      "     classification:  Generation  =  5\n",
      " Type 2 :  Water\n",
      "     classification:  Generation  =  1\n",
      " Type 2 :  Rock\n",
      "     classification:  Generation  =  3\n",
      " Type 2 :  Flying\n",
      "     classification:  Generation  =  1\n",
      " Type 2 :  Ice\n",
      "     classification:  Generation  =  1\n",
      " Type 2 :  Dark\n",
      "     classification:  Generation  =  3\n",
      " Type 2 :  Ghost\n",
      "     classification:  Generation  =  5\n",
      " Type 2 :  Dragon\n",
      "     classification:  Generation  =  6\n",
      " Type 2 :  nan\n",
      "     classification:  Generation  =  \n",
      " Type 2 :  Ground\n",
      "     classification:  Generation  =  2\n",
      " Type 2 :  Normal\n",
      "     classification:  Generation  =  6\n"
     ]
    }
   ],
   "source": [
    "# 1. load data\n",
    "data = pd.read_csv(\"data/pokemon_no_duplicates.csv\")\n",
    "\n",
    "# 2. prepare data\n",
    "#data = prepare_data(data)\n",
    "\n",
    "# choose the target value\n",
    "data = data.drop(columns=[\"Name\", \"#\"])\n",
    "target = \"Generation\"\n",
    "attributes = list(data.columns)\n",
    "attributes.remove(target)\n",
    "# 3. split_data with id3\n",
    "rootNode = Node()\n",
    "decisionTree = train_data(data=data, target=target, attributes=attributes, node=rootNode, recursion_depth=0)\n",
    "decisionTree.id3()\n",
    "\n",
    "rootNode.printTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "683fee35",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No axis named 5 for object type DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\scipy\\lib\\site-packages\\pandas\\core\\generic.py:550\u001b[0m, in \u001b[0;36mNDFrame._get_axis_number\u001b[1;34m(cls, axis)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_AXIS_TO_AXIS_NUMBER\u001b[49m\u001b[43m[\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 5",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m datapoints \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, test_data(datapoints, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m, rootNode)\u001b[38;5;241m.\u001b[39maccuracy() )\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifications: \u001b[39m\u001b[38;5;124m\"\u001b[39m, test_data(datapoints, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m, rootNode)\u001b[38;5;241m.\u001b[39mclassify())\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\scipy\\lib\\site-packages\\pandas\\core\\indexing.py:634\u001b[0m, in \u001b[0;36m_LocationIndexer.__call__\u001b[1;34m(self, axis)\u001b[0m\n\u001b[0;32m    631\u001b[0m new_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 634\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_axis_number\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m new_self\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m axis\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_self\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\scipy\\lib\\site-packages\\pandas\\core\\generic.py:552\u001b[0m, in \u001b[0;36mNDFrame._get_axis_number\u001b[1;34m(cls, axis)\u001b[0m\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_AXIS_TO_AXIS_NUMBER[axis]\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 552\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo axis named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for object type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: No axis named 5 for object type DataFrame"
     ]
    }
   ],
   "source": [
    "\n",
    "datapoints = data.loc(5)\n",
    "\n",
    "print(\"accuracy: \", test_data(datapoints, \"Generation\", rootNode).accuracy() )\n",
    "print(\"classifications: \", test_data(datapoints, \"Generation\", rootNode).classify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2e8a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
