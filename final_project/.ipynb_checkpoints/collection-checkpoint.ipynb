{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d74cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3288cbdc",
   "metadata": {},
   "source": [
    "### Node Class\n",
    "\n",
    "Tree structure is build by Node Objects. Each node object has an attribute and a classification when trained, as well as a parent node and the value associated with the parents attribute and a classification.\n",
    "The nodes are trained by tran_data and also offer the printTree function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89cdb6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    '''\n",
    "    class Node innitialises a tree structure for a non-binary tree\n",
    "    it has the typical setter and getter methods and a method to remove a \n",
    "    child from the list of children\n",
    "    '''\n",
    "    def __init__(self, parent = None, attribute = None, classification = None, value = None, target = None):\n",
    "        self.children = []  \n",
    "        self.parent = parent\n",
    "        self.attribute = attribute\n",
    "        self.classification = classification\n",
    "        self.value = value\n",
    "        self.target = target\n",
    "        \n",
    "\n",
    "    def setChild(self, node):\n",
    "        self.children.append(node)\n",
    "        \n",
    "    def setParent(self, node):\n",
    "        if (self.parent is not None):\n",
    "            self.parent.children.remove(self)\n",
    "        self.parent = node\n",
    "\n",
    "    def getChildren(self):\n",
    "        return self.children\n",
    "    \n",
    "    def getParent(self):\n",
    "        return self.parent\n",
    "    \n",
    "    def deleteChild(self, node):\n",
    "        if (node in self.children):\n",
    "            node.parent = None\n",
    "            self.children.remove(node)\n",
    "        else:\n",
    "            raise TypeError(\"Child not in Children\")\n",
    "        \n",
    "    def isLeaf(self):\n",
    "        if len(self.children) > 0:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def isRoot(self):\n",
    "        if (self.parent is None):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def setAttribute(self, attribute):\n",
    "        self.attribute = attribute\n",
    "    \n",
    "    def getAttribute(self):\n",
    "        return self.attribute\n",
    "    \n",
    "    def setClassification(self, classification):\n",
    "        self.classification = classification\n",
    "    \n",
    "    def getClassification(self):\n",
    "        return self.classification\n",
    "    \n",
    "    def setValue(self,value):\n",
    "        self.value = value\n",
    "\n",
    "    def getValue(self):\n",
    "        return self.value\n",
    "    \n",
    "\n",
    "    def printTree(self, level = 0):\n",
    "        tab = \"    \"\n",
    "        if self.isLeaf():\n",
    "            print(tab*level, \"classification: \", self.target, \" = \" , self.classification)\n",
    "        else:\n",
    "            for child in self.children:\n",
    "                print(tab*level, self.attribute, \": \", child.value)\n",
    "                child.printTree(level + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138bae1f",
   "metadata": {},
   "source": [
    "### train_Data Class\n",
    "\n",
    "The class represents a data (sub)set that is used to train the (sub)tree. It has a (root) node which it is responsible to train (choose attribute, classification, and child nodes) via the id3 function.\n",
    "I can also deal with continuous variables by ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35cbed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_data:\n",
    "    '''\n",
    "    class train_data has all important functions for ID3 Algorithm:\n",
    "    it can calculate the entropy of some data, the information gain, choose an attriute.\n",
    "    within the ID3 algorithm a tree will be trained.\n",
    "    the function retrain(data) retrains a trained tree with new data.\n",
    "    '''\n",
    "    def __init__(self, data, target, attributes, node:Node = None, recursion_depth = None, continuous_splitting = 0.1,  max_recursion = 10):\n",
    "        \n",
    "        self.data = data\n",
    "        if not isinstance(self.data, pd.DataFrame):\n",
    "            raise TypeError(\"Data has to be a Pandas Dataframe\")\n",
    "        \n",
    "        self.target = target\n",
    "        if not isinstance(self.target, str):\n",
    "            raise TypeError(\"Taget has to be of type string\")\n",
    "        \n",
    "        self.attributes = attributes\n",
    "        if not isinstance(attributes, list):\n",
    "            raise TypeError(\"Attributes have to have structure list\")\n",
    "            \n",
    "        for attribute in self.attributes:\n",
    "            if not isinstance(attribute, str):\n",
    "                raise TypeError(\"Attributes have to be of type string\")\n",
    "\n",
    "        self.node = node\n",
    "        self.continuous_splitting = continuous_splitting\n",
    "        self.recursion_depth = recursion_depth\n",
    "        self.max_recursion = max_recursion\n",
    "    \n",
    "    def is_continuous(self, values):\n",
    "        # checks is variable is a continuous variable\n",
    "        if len(values) > 10:\n",
    "            for value in values:\n",
    "                if value is not int or float:\n",
    "                    return False\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def attribute_continuous(self, attributeColumn, values):\n",
    "        \n",
    "        # sort the set\n",
    "        values = list(sorted(values))\n",
    "        split_lenght = int(len(values) * self.continuous_splitting)\n",
    "        maxGain = 0\n",
    "        maxValue = 0\n",
    "        for split in range(split_lenght):\n",
    "            value = values[split]\n",
    "\n",
    "            subsetData1 = self.data[attributeColumn <= value]\n",
    "            subsetData2 = self.data[attributeColumn > value]\n",
    "            subset1 = train_data(subsetData1, self.target, self.attributes)\n",
    "            subset2 = train_data(subsetData2, self.target, self.attributes)\n",
    "\n",
    "            gainSum =  (subsetData1.shape[0] / self.data.shape[0]) * subset1.entropy() + (subsetData2.shape[0] / self.data.shape[0]) * subset2.entropy()\n",
    "            infoGain = self.data.entropy() - gainSum\n",
    "\n",
    "            if infoGain > maxGain:\n",
    "                maxGain = infoGain\n",
    "                maxValue = value\n",
    "        \n",
    "        return [maxGain, maxValue]\n",
    "\n",
    "    def entropy(self):\n",
    "        targetColumn = self.data.loc[:, self.target]\n",
    "\n",
    "        values = set(targetColumn)\n",
    "        entropySum = 0\n",
    "        for value in values:\n",
    "            # p = targetColumn.count(value) / len(targetColumn)\n",
    "            valueColumn = self.data[targetColumn == value].loc[:, self.target]\n",
    "            p = len(valueColumn)/ len(targetColumn)\n",
    "            entropySum = entropySum + (- p * np.log(p))\n",
    "\n",
    "        return entropySum\n",
    "    \n",
    "\n",
    "    def informationGain(self, attributeColumn, values):\n",
    "        gainSum = 0\n",
    "        \n",
    "        for value in values:\n",
    "            \n",
    "            subsetData = self.data[attributeColumn == value]\n",
    "            subset = train_data(subsetData, self.target, self.attributes)\n",
    "            # claculate entropy and normalize by size of subsets\n",
    "            gainSum = gainSum + (subsetData.shape[0] / self.data.shape[0]) * subset.entropy()\n",
    "\n",
    "        # substract summed and weighted entropy of subsets from entropy of whole set    \n",
    "        infoGain = self.entropy() - gainSum\n",
    "\n",
    "        return infoGain\n",
    "\n",
    "\n",
    "    def chooseAttribute(self):\n",
    "        maxGain= 0\n",
    "        maxAttribute = \"\"\n",
    "\n",
    "        # calculate Information Gain for each attribute\n",
    "        for attribute in self.attributes:\n",
    "            attributeColumn = self.data.loc[:, attribute]\n",
    "            values = set(attributeColumn)\n",
    "            gain = 0\n",
    "\n",
    "            # calculate Information gain for this attribute\n",
    "            if self.is_continuous(values):\n",
    "                gain = self.attribute_continuous(attributeColumn, values)[0] # calculates the split information ???\n",
    "            else:\n",
    "                gain = self.informationGain(attributeColumn, values)\n",
    "\n",
    "            # store attribute with highest information gain\n",
    "            if gain >= maxGain:\n",
    "                maxGain = gain\n",
    "                maxAttribute = attribute\n",
    "\n",
    "        # choose attribute with highest Information Gain\n",
    "        return maxAttribute\n",
    "\n",
    "    def classify(self):\n",
    "        # returns the most commen classification of the dataset\n",
    "        \n",
    "        targetColumn = self.data.loc[:, self.target]\n",
    "        values = set(targetColumn)\n",
    "        maxClass = 0\n",
    "        classification = \"\"\n",
    "        for value in values:\n",
    "            \n",
    "            # if targetColumn.count(value) > maxClass:\n",
    "            valueColumn = self.data[targetColumn == value].loc[:, self.target]\n",
    "            if len(valueColumn) > maxClass:\n",
    "                maxClass = len(valueColumn)\n",
    "                classification = value\n",
    "\n",
    "        return classification\n",
    "\n",
    "\n",
    "    def remove_attribute(self, attribute):\n",
    "        self.attributes.remove(attribute)\n",
    "        return self.attributes\n",
    "\n",
    "    def id3(self):\n",
    "        # base cases:\n",
    "        # 1) all instances have same target value -> leaf node with target value\n",
    "        if (self.data[self.target].nunique() == 1):\n",
    "            self.node.setClassification(self.data[self.target].iloc[0])\n",
    "            print(\"basecase1\")\n",
    "            return \n",
    "        # 2) out of discriptive features -> leaf node with majority of target values\n",
    "        if (not self.attributes):\n",
    "            self.node.setClassification(self.classify())\n",
    "            print(\"basecase2\")\n",
    "            return\n",
    "        # 3) no instances left in dataset -> take majority of parent node\n",
    "        if (self.data is None):\n",
    "            parent = self.node.getParent()\n",
    "            self.node.setClassification(parent.getClassification())\n",
    "            print(\"basecase3\")\n",
    "            return\n",
    "        # 4) maximal recursion depth:\n",
    "        if self.recursion_depth == self.max_recursion:\n",
    "            self.node.setClassification(self.classify())\n",
    "            print(\"basecase4\")\n",
    "            return\n",
    "\n",
    "\n",
    "        # recursive case:\n",
    "        # choose attribute with highest explainatory power\n",
    "        print(\"in recursion\")\n",
    "        print(\"attributs: \", self.attributes)\n",
    "        attribute = self.chooseAttribute()\n",
    "        self.node.setAttribute(attribute)\n",
    "        self.node.setClassification(self.classify())\n",
    "\n",
    "        # split data according to attribute\n",
    "        attributeColumn = self.data.loc[:, attribute]\n",
    "        values = set(attributeColumn)\n",
    "        new_attributes = self.remove_attribute(attribute)\n",
    "        recursion_depth = self.recursion_depth + 1\n",
    "\n",
    "        # chosen attribute is a continuous variable:\n",
    "        if self.is_continuous(values):\n",
    "            print(\"continuous\")\n",
    "            value = self.attribute_continuous(attributeColumn, values)[1]\n",
    "\n",
    "            subsetData1 = self.data[attributeColumn <= value]\n",
    "            subsetData2 = self.data[attributeColumn > value]\n",
    "            childNode1 = Node(parent=self.node, value=f\"<= {value}\")\n",
    "            childNode2 = Node(parent=self.node, value=f\"> {value}\")\n",
    "            self.node.setChild(childNode1)\n",
    "            self.node.setChild(childNode2)\n",
    "            \n",
    "            subset1 = train_data(data=subsetData1, target=self.target, attributes=new_attributes, node=childNode1, recursion_depth=recursion_depth)\n",
    "            subset2 = train_data(data=subsetData2, target=self.target, attributes=new_attributes, node=childNode2, recursion_depth=recursion_depth)\n",
    "            # recursive call on all partitions\n",
    "            subset1.id3()\n",
    "            subset2.id3()\n",
    "        \n",
    "        # chosen attribute is a categorical variable:\n",
    "        else:\n",
    "            print(\"not continuous\")\n",
    "            for value in values:\n",
    "                subsetData = self.data[attributeColumn == value]\n",
    "                childNode = Node(parent=self.node, value=value, target=self.target)\n",
    "                self.node.setChild(childNode)\n",
    "                subset = train_data(data=subsetData, target=self.target, attributes=new_attributes, node=childNode, recursion_depth=recursion_depth)\n",
    "    \n",
    "                # recursive call on all partitions\n",
    "                subset.id3()\n",
    "\n",
    "    def retrain(self, data):\n",
    "        self.data = data\n",
    "        self.id3()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed29ff3",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1127ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "d= {\"gender\": [\"f\", \"f\", \"f\", \"f\", \"f\", \"m\", \"m\", \"m\", \"m\", \"m\"],\n",
    "                   \"vegan\": [True, True, True, False, False, True, False, False, False, False],\n",
    "                   \"coxi\": [True, True, True, False, True, True, True, False, False, False],\n",
    "                   \"green\": [True, True, True, False, False, True, False, True, False, True]}\n",
    "\n",
    "data = pd.DataFrame(data = d)\n",
    "\n",
    "target = \"vegan\"\n",
    "attributes = list(data.columns)\n",
    "attributes.remove(target)\n",
    "\n",
    "rootNode = Node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c11127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb106889",
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTree = train_data(data=data, target=target, attributes=attributes, node=rootNode, recursion_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5826927b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in recursion\n",
      "attributs:  ['gender', 'coxi', 'green']\n",
      "not continuous\n",
      "basecase1\n",
      "in recursion\n",
      "attributs:  ['gender', 'coxi']\n",
      "not continuous\n",
      "basecase1\n",
      "basecase1\n"
     ]
    }
   ],
   "source": [
    "decisionTree.id3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b72aab71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " green :  False\n",
      "     classification:  vegan  =  False\n",
      " green :  True\n",
      "     coxi :  False\n",
      "         classification:  vegan  =  False\n",
      "     coxi :  True\n",
      "         classification:  vegan  =  True\n"
     ]
    }
   ],
   "source": [
    "rootNode.printTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388031cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
